\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{amssymb}
\usepackage{hyperref}

\title{Fast Fourier Transform -- Analyzing and Modifying Digital Audio Frequency Content}
\author{A.J. Rideout}
\date{January 2026}

\begin{document}

\maketitle

\section{Declaration of Use of Generative AI:} Generative language models have been used to debug and refine hand-written python code used within this assignment, as well as to quickly retrieve information from documentation of used libraries. 

\section{Abstract} Fast Fourier transform algorithms are the standard way to calculate the discrete Fourier transform in most practical applications. In the case of digital audio, the Fourier transform is especially valuable for analysis and modification of audio signals. It allows us to not only characterize signals, but shape their sound through modification of frequency content. This is known as filtering, and it is one of the most fundamental methods of altering sound, and it can be accomplished in many ways. After developing a fast Fourier transform algorithm, we develop and refine a simple frequency-domain filter. We first created an ideal filter, which has drawbacks through the Gibbs effect. We used a window function, the Hanning window, to combat the ringing and overshoot known as the Gibbs effect, creating a more usable, stable filter.

\section{Introduction} The Fourier transform is intuitively valuable when analyzing audio signals, as breaking down a more complex town into a series of frequencies that compose it allows one to intuitively understand the fundamental building blocks that construct a sound and contribute to its character. In most cases however, calculating the Fourier transform can be costly and time consuming -- especially as the signal reaches larger sizes. Luckily, there exist alternative means/routes to calculating the Discrete Fourier Transform (DFT) for a dataset, which lead to alternative results. These often exploit symmetries or properties of the signal to introduce "shortcuts" that allow reduced operations to calculate the transform. For example, the Cooley-Tukey algorithm operates exclusively on data sets of size $2^n$, and takes advantage of symmetries in the exponential terms to introduce a recursive "divide-and-conquer" approach that breaks the larger DFT into a series of smaller problems that in all significantly reduce the workload required. \cite{1}
Once a Fourier Transform is obtained, for observations sake we really only use the first $N/2$ coefficients, as for real-valued functions (which audio signals tend to be!) the Fourier transform will have a conjugate symmetry. \cite{2} However, we do still need the data after that if we plan on using the Inverse Fourier transform on the DFT data to obtain our original signal. Being able to return to our original signal is especially important if we plan on making changes in the frequency-domain DFT data. Any changes we make within the frequency-domain will be present in the output of the inverse FFT. This effectively allows us to shape our sounds by controlling the presence of individual frequencies. This is known as filtering, and there exist many ways of doing so, but altering the frequency domain, while not conducive to modern workflow standards, is a great demonstration of filtering as a concept and the control that obtaining the DFT of our audio can grant us. 

\section{Method}  The Fourier transform is an integral transform that decomposes a function over a continuous domain into a spectrum of complex exponential elements, each corresponding to some frequency that is present within the original data. For each element, there exists a coefficient that denotes that frequencies presence within the signal, with a higher value indicating an abundance of that frequency. The $n$th Fourier coefficient, $\hat{f}(n)$, is defined as: \[\hat{f}(n)=\int_{\mathbb{T}^1}f(x)e^{-2\pi inx}\space dx\]
where $\mathbb{T}^1$ defines the one dimensional torus: $\mathbb{R}/\mathbb{Z}$. \cite{1}. The Fourier transform is similarly defined: \[\hat{f}(\xi)=\int_{\mathbb{R}}f(x)e^{-2\pi ix\xi}\space dx\] These definitions are derived from the inner product of a space created over $\mathbb{T}^1$, where each exponential $e^{-2\pi inx}$ (which we may denote as $e_n$) is orthogonal to each other \cite{1} and refers to a specific amount of rotations about $\mathbb{T}$. By taking the inner product of our function $f(x)$ with $e_n$, we are essentially finding a projection of our function onto the amount of rotations corresponding to $e_n$, which is larger in magnitude when it corresponds highly to $e_n$. 
When working with digital audio signals, an important thing to keep in mind is that audio signals are discrete. They consist of a series of samples that represent the amplitude of our sound at a given time. The rate at which samples are taken in and played back at is known as the sample rate. While initially sample rate may seem arbitrary, it is important for time-based signals that the sample rate properly accommodates our data without using up too much space. The Nyquist-Shannon sampling theorem states that in order for a signal to be reproduced perfectly digitally, it must have a sample rate that is at least double the highest relevant frequency of study. \cite{3} In the case of audio, a common standard is 44100 Hz., as that well accommodates the human range of hearing, with most people struggling with frequencies above 20000 Hz.. Because we will be working with discrete data, we cannot use the main definition of the Fourier transform. Luckily, a lot of the concepts behind the Fourier transform carry well into discrete domains. The $n$th Fourier coefficient for a discrete domain function/dataset is defined as: \[\hat{f}(n)=\frac{1}{\sqrt{N}}\sum_{k=0}^{N-1}f(k)e^{{-2\pi ikn}/N}\] \cite{1} Where $N$ is the total number of samples in our data set. Note that the $\frac{1}{\sqrt{N}}$ factor is not necessary for application on digital audio, especially if we are normalizing our audio (scaling it to the highest amplitude it contains) before and after our transform. The concepts behind translating over to a discrete domain are similar -- $e_n=e^{{-2\pi ikn}/N}$ in this case is an $N$th root of unity, which similarly can communicate a complex number having completed $n$ rotations about a unit circle. Thus, in taking a discrete inner product between $f$ and $e_n$ we are similarly probing for correlation between $f$ and the frequency $e_n$ denotes, where $f$ having a stronger match to the oscillation of $e_n$ indicates a higher coefficient at $n$. We can go from Fourier coefficients back to $f$ by the inverse discrete Fourier transform: \[f=\sum^{N-1}_{n=0}\hat{f}(n)e^{{2\pi ikn}/N}\] \cite{1} noting that the sign of the exponent is flipped.
With this definition of the DFT, we can retrieve the coefficients of our sound data, analyze or modify them, and convert them back into our original signal. However, doing so, especially for large $N$, is computationally expensive, and often not calculated according to this definition. Instead, there exist widely-used fast Fourier transform (FFT) algorithms that use alternate, less intensive calculations that yield the same result as the DFT. Many take advantage of existing symmetries of the DFT for signals with specific characteristics. One widely used example of an FFT algorithm is the Cooley-Tukey (Radix-2) algorithm, which operates specifically on data sets of size $N=2^n$. The algorithm reduces the required operations from $O(N^2)$ operations to $O(N log_2N)$ operations. \cite{1} Essentially, what the algorithm does, 


\begin{thebibliography}{9}
\bibitem{1} 
Bounchalen, Anna. \textit{An Elementary Introduction to Fast Fourier Transform Algorithms}. University of Chicago Mathematics REU, 2019. \url{https://math.uchicago.edu/~may/REU2019/REUPapers/Bounchaleun.pdf}

\bibitem{2}
https://brianmcfee.net/dstbook-site/content/ch06-dft-properties/Conjugate-Symmetry.html

\bibitem{3}
Keim, Robert. \textit{The Nyquist-Shannon Theorem: Understanding Sampled Systems - Technical Articles.}. All About Circuits, May 6 2020. \url{https://www.allaboutcircuits.com/technical-articles/nyquist-shannon-theorem-understanding-sampled-systems/}
\end{thebibliography}

\end{document}
